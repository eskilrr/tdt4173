{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix,recall_score,precision_score,f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data():\n",
    "    df_test = pd.read_csv(r'test_data.csv', sep = \",\")\n",
    "    df_train = pd.read_csv(r'train_data.csv', sep = \",\")\n",
    "\n",
    "    test = df_test.drop(df_test.columns[0],axis=1)\n",
    "\n",
    "    test_targets = test.iloc[:,[13]]\n",
    "    test_inputs = test.loc[:,test.columns != 'target']\n",
    "\n",
    "    train = df_train.drop(df_train.columns[0],axis=1)\n",
    "    train_targets = train.iloc[:,[13]]\n",
    "    train_inputs = train.loc[:,train.columns != 'target']\n",
    "    \n",
    "    np.savez('Spotify_data_train', inputs=train_inputs, targets=train_targets)\n",
    "    np.savez('Spotify_data_test', inputs=test_inputs, targets=test_targets)\n",
    "\n",
    "    npz = np.load('Spotify_data_train.npz')\n",
    "    train_inputs,train_targets = npz['inputs'].astype(np.float),npz['targets'].astype(np.int)\n",
    "\n",
    "    npz = np.load('Spotify_data_test.npz')\n",
    "    test_inputs, test_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n",
    "\n",
    "    test_inputs = preprocessing.scale(test_inputs)\n",
    "    train_inputs = preprocessing.scale(train_inputs)\n",
    "    \n",
    "    return train_inputs,train_targets,test_inputs,test_targets\n",
    "\n",
    "train_inputs,train_targets,test_inputs,test_targets = process_data()\n",
    "\n",
    "total_samples = len(train_inputs)\n",
    "split = math.ceil(total_samples/5)\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluering av metoden med hyperparametre fra ModelCross"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forklarende tekst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_nodes,n_layers):\n",
    "    \n",
    "    input_size = 18\n",
    "    output_size = 1\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    #Specifying input shape in the dense layer, Keras automaticly adds an input layer.\n",
    "    model.add(layers.Dense(n_nodes, activation='relu',input_shape=(input_size,)))\n",
    "    for i in range(n_layers-1):\n",
    "        model.add(layers.Dense(n_nodes,kernel_regularizer=tf.keras.regularizers.l2(0.001), activation='relu'))\n",
    "    #model.add(layers.Dense(output_size, activation='softmax'))\n",
    "    model.add(layers.Dense(output_size, activation='sigmoid'))\n",
    "    \n",
    "    return model\n",
    "    \n",
    "def compile_model(model,chosen_optimizer):\n",
    "    #Decreases the learning rate with a factor of 0.9, every 10 000 steps. \n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=1e-2,\n",
    "        decay_steps=10000,\n",
    "        decay_rate=0.9)\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "    #model.compile(optimizer=chosen_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.compile(optimizer=optimizer, loss=tf.keras.losses.BinaryCrossentropy(), metrics=['accuracy'])\n",
    "    \n",
    "def fit_model(model,b_size,m_epochs):\n",
    "    \n",
    "    batch_size = b_size\n",
    "    max_epochs = m_epochs\n",
    "    \n",
    "    history = model.fit(  train_inputs,train_targets,\n",
    "                          batch_size=batch_size,\n",
    "                          epochs=max_epochs,\n",
    "                          validation_split = 0.2,\n",
    "                          #validation_data=(v_inputs, v_targets),\n",
    "                          #callbacks=[\n",
    "                                #tf.keras.callbacks.TensorBoard(run_dir,histogram_freq=1,update_freq=1,embeddings_freq=1),\n",
    "                                #tf.keras.callbacks.EarlyStopping(\n",
    "                                    #monitor='val_accuracy', min_delta=0.001, patience=5, mode='max',\n",
    "                                    #baseline=None),\n",
    "                                #tf.keras.callbacks.EarlyStopping(\n",
    "                                    #monitor='val_loss', min_delta=0.001, patience=7, verbose=0, mode='min',\n",
    "                                    #baseline=0.6)\n",
    "                                #],\n",
    "                              verbose = 1) \n",
    "    return history\n",
    "\n",
    "\n",
    "def plot_history(history):\n",
    "    \n",
    "    training_loss = history.history['loss']\n",
    "    validation_loss = history.history['val_loss']\n",
    "    accuracy = history.history['accuracy']\n",
    "    epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "    \n",
    "    plt.plot(epoch_count, training_loss, 'r--')\n",
    "    plt.plot(epoch_count, validation_loss, 'b-')\n",
    "    plt.plot(epoch_count,accuracy)\n",
    "    plt.legend(['Training Loss', 'Validation Loss','Accuracy'])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show();\n",
    "    \n",
    "def evaluate_model(model):\n",
    "    test_loss, test_accuracy = model.evaluate(test_inputs, test_targets)\n",
    "    print('\\nTest loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))\n",
    "    \n",
    "def predict(model,inputs):\n",
    "    predictions = model.predict(inputs)\n",
    "    predictions_arr = np.argmax(predictions,axis=1)\n",
    "    return predictions,predictions_arr\n",
    "  \n",
    "    \n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    true_label = test_targets[i]\n",
    "    plt.grid(False)\n",
    "\n",
    "    thisplot = plt.bar(range(2), predictions_array, color=\"#777777\")\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    \n",
    "    if predicted_label == true_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    "    \n",
    "    plt.ylabel(\"{:2.0f}%\".format(100*np.max(predictions_array),color=color))\n",
    "\n",
    "    \n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[true_label[0]].set_color('blue')\n",
    "    \n",
    "def plot_result(rows,cols,predictions):\n",
    "    plt.figure(figsize=(2*2*cols, 2*rows))\n",
    "    for i in range(rows*cols):\n",
    "        plt.subplot(rows, 2*cols, 2*i+2)\n",
    "        plot_value_array(i, predictions[i], test_targets)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def get_wrong_guess_data(predictions):\n",
    "    wrong_guess = []\n",
    "    for i in range(100):\n",
    "        index = np.argmax(predictions[i])\n",
    "        if(index!=test_targets[i]):\n",
    "            arr = np.concatenate((test_inputs[i],test_targets[i])) \n",
    "            wrong_guess.append(arr)\n",
    "            #wrong_guess.append(test_targets[i])\n",
    "    return wrong_guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n_nodes,n_layers,optimizer,b_size,m_epochs):\n",
    "    model = build_model(n_nodes,n_layers)\n",
    "    compile_model(model,optimizer)\n",
    "    history = fit_model(model,b_size,m_epochs)\n",
    "    evaluate_model(model)\n",
    "    \n",
    "    predictions,predictions_arr = predict(model,test_inputs)\n",
    "    plot_result(2,2,predictions)\n",
    "    wrong_guesses = get_wrong_guess_data(predictions)\n",
    "    print(' \\nConfusion Matrix: \\n',confusion_matrix(test_targets, predictions_arr))\n",
    "    print('\\nF1 Score:',f1_score(test_targets,predictions_arr))\n",
    "    print('\\nRecall Score:',recall_score(test_targets,predictions_arr))\n",
    "    print('\\nPrecision Score:',precision_score(test_targets,predictions_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model(5,5,'adam',200,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1950/1950 [==============================] - 2s 1ms/step - loss: 0.6094 - accuracy: 0.6721 - val_loss: 0.5482 - val_accuracy: 0.7288\n",
      "Epoch 2/15\n",
      "1950/1950 [==============================] - 2s 1ms/step - loss: 0.5393 - accuracy: 0.7316 - val_loss: 0.5293 - val_accuracy: 0.7374\n",
      "Epoch 3/15\n",
      "1950/1950 [==============================] - 2s 988us/step - loss: 0.5254 - accuracy: 0.7364 - val_loss: 0.5222 - val_accuracy: 0.7444\n",
      "Epoch 4/15\n",
      "1950/1950 [==============================] - 2s 967us/step - loss: 0.5201 - accuracy: 0.7377 - val_loss: 0.5176 - val_accuracy: 0.7435\n",
      "Epoch 5/15\n",
      "1950/1950 [==============================] - 2s 990us/step - loss: 0.5175 - accuracy: 0.7387 - val_loss: 0.5184 - val_accuracy: 0.7374\n",
      "Epoch 6/15\n",
      "1950/1950 [==============================] - 2s 988us/step - loss: 0.5146 - accuracy: 0.7419 - val_loss: 0.5147 - val_accuracy: 0.7415\n",
      "Epoch 7/15\n",
      "1950/1950 [==============================] - 2s 988us/step - loss: 0.5128 - accuracy: 0.7417 - val_loss: 0.5106 - val_accuracy: 0.7431\n",
      "Epoch 8/15\n",
      "1950/1950 [==============================] - 2s 985us/step - loss: 0.5108 - accuracy: 0.7430 - val_loss: 0.5095 - val_accuracy: 0.7476\n",
      "Epoch 9/15\n",
      "1950/1950 [==============================] - 2s 1ms/step - loss: 0.5085 - accuracy: 0.7472 - val_loss: 0.5117 - val_accuracy: 0.7435\n",
      "Epoch 10/15\n",
      "1950/1950 [==============================] - 2s 1ms/step - loss: 0.5069 - accuracy: 0.7441 - val_loss: 0.5069 - val_accuracy: 0.7526\n",
      "Epoch 11/15\n",
      "1950/1950 [==============================] - 3s 1ms/step - loss: 0.5062 - accuracy: 0.7447 - val_loss: 0.5063 - val_accuracy: 0.7513\n",
      "Epoch 12/15\n",
      "1950/1950 [==============================] - 2s 963us/step - loss: 0.5054 - accuracy: 0.7485 - val_loss: 0.5067 - val_accuracy: 0.7464\n",
      "Epoch 13/15\n",
      "1950/1950 [==============================] - 2s 1ms/step - loss: 0.5048 - accuracy: 0.7453 - val_loss: 0.5032 - val_accuracy: 0.7530\n",
      "Epoch 14/15\n",
      "1950/1950 [==============================] - 2s 893us/step - loss: 0.5038 - accuracy: 0.7480 - val_loss: 0.5045 - val_accuracy: 0.7489\n",
      "Epoch 15/15\n",
      "1950/1950 [==============================] - 2s 892us/step - loss: 0.5036 - accuracy: 0.7487 - val_loss: 0.5033 - val_accuracy: 0.7505\n",
      " 1/96 [..............................] - ETA: 0s - loss: 0.4835 - accuracy: 0.7812WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "96/96 [==============================] - 0s 634us/step - loss: 0.5050 - accuracy: 0.7462\n",
      "\n",
      "Test loss: 0.51. Test accuracy: 74.62%\n"
     ]
    }
   ],
   "source": [
    "model = build_model(5,2)\n",
    "compile_model(model,'RMSprop')\n",
    "history = fit_model(model,5,15)\n",
    "evaluate_model(model)\n",
    "predictions,predictions_arr = predict(model,test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard.notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
